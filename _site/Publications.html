<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.563">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Perception, Action, and Development Lab -</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<script src="site_libs/core-js-2.5.3/shim.min.js"></script>
<script src="site_libs/react-17.0.0/react.min.js"></script>
<script src="site_libs/react-17.0.0/react-dom.min.js"></script>
<script src="site_libs/reactwidget-1.0.0/react-tools.js"></script>
<script src="site_libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="site_libs/reactable-binding-0.3.0/reactable.js"></script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="./index.html">
    <img src="./images/icon-plain.png" alt="">
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html">Home</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./Publications.html" aria-current="page">Publications</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./People.html">People</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./Contact.html">Contact</a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#publications" id="toc-publications" class="nav-link active" data-scroll-target="#publications">Publications</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">



<section id="publications" class="level1 column-page-inset">
<h1>Publications</h1>
<div class="cell">

</div>
<div class="cell">
<div class="cell-output-display">

<div id="cars-select" class="reactable html-widget" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="cars-select">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"year":[2022,2021,2021,2021,2021,2020,2022,2020,2020,2020,2020,2020,2019,2019,2018,2018,2018,2018],"abstract":["The current study investigated how infants (6-24 months), children (2-12 years), and adults differ in how visual cues—visual saliency and centering—guide their attention to faces in videos. We report a secondary analysis of Kadooka and Franchak (2020), in which observers’ eye movements were recorded during viewing of television clips containing a variety of faces. For every face on every video frame, we calculated its visual saliency (based on both static and dynamic image features) and calculated how close the face was to the center of the image. Results revealed that participants of every age looked more often at each face when it was more salient compared to less salient. In contrast, centering did not increase the likelihood that infants looked at a given face, but in later childhood and adulthood centering became a stronger cue for face looking. A control analysis determined that the age-related change in centering was specific to face looking; participants of all ages were more likely to look in the center of the image, and this center bias did not change with age. The implications for using videos in educational and diagnostic contexts are discussed.","How can researchers best measure infants' motor experiences in the home? Body position—whether infants are held, supine, prone, sitting, or upright—is an important developmental experience. However, the standard way of measuring infant body position, video recording by an experimenter in the home, can only capture short instances, may bias measurements, and conflicts with physical distancing guidelines resulting from the COVID-19 pandemic. Here, we introduce and validate an alternative method that uses machine learning algorithms to classify infants' body position from a set of wearable inertial sensors. A laboratory study of 15 infants demonstrated that the method was sufficiently accurate to measure individual differences in the time that infants spent in each body position. Two case studies showed the feasibility of applying this method to testing infants in the home using a contactless equipment drop-off procedure.","How are eyes and head adapted to meet the demands of visual exploration in different tasks and environments? In two studies, we measured the horizontal movements of the eyes (using mobile eye tracking in Studies 1 and 2) and the head (using inertial sensors in Study 2) while participants completed a walking task and a search and retrieval task in a large, outdoor environment. We found that the spread of visual exploration was greater while searching compared with walking, and this was primarily driven by increased movement of the head as opposed to the eyes. The contributions of the head to gaze shifts of different eccentricities was greater when searching compared to when walking. Findings are discussed with respect to understanding visual exploration as a motor action with multiple degrees of freedom.","What makes a task hard or easy? The question seems easy, but answering it has been hard. The only consensus has been that, all else being equal, easy tasks can be performed by more individuals than hard tasks, and easy tasks are usually preferred over hard tasks. Feghhi and Rosenbaum (Journal of Experimental Psychology: Human Perception and Performance, 45, 983–994, 2019) asked whether task difficulty might reflect a single amodal quantity. Based on their subjects’ two-alternative forced-choice data from tasks involving choices of tasks with graded physical and mental challenges, the authors showed that the difficulty of passing through a narrow gap rather than a wide gap was psychologically equivalent to memorizing an extra .55 digits. In the present study, we extended this approach by adding new arguments for the hypothesis that task difficulty might reflect a single amodal quantity (inspired by considerations of physics, economics, and the common code hypothesis for the study of perception and action), and we tested narrower gaps than before to see whether we would find a larger equivalent memory-digit. Consistent with our prediction, we obtained a value of .95. We suggest that our multi-modal two-alternative forced-choice procedure can pave the way toward a better understanding of task difficulty.","Immersive virtual environments (VEs) are most useful for training and education when viewers perceive and act accurately within them. Judgments of action capabilities within a VE provide a good measure of perceptual fidelity — the notion of how closely perception and action in the VE match that in the real world — and can also assess how perception for action may be calibrated with visual feedback based on one’s own actions. In the current study we tested judg- ments of action capabilities within a VE for two different reaching behaviors: reaching out and reaching up. Our goal was to assess whether feedback from actual reaching improves judgments and if any recalibration due to feedback differed across reaching behaviors. We first measured participants’ actual reaching out and reaching up capabilities so that feedback trials could be scaled to their actual abil- ities. Participants then completed blocks of alternating perceptual adjustment and feedback trials. In adjustment trials, they adjusted a virtual target to a distance perceived to be just reachable. In feedback trials, they viewed targets that were farther or closer than their actual reach, decided whether the target was reachable, and then reached out to the target to receive visual feedback from a hand-held con- troller. The first feedback block manipulated the target distance to be 30% over or under actual reach and subsequent blocks decreased the deviation to 20%, 10% and 5% of actual reach. We found that for both reaching behaviors, reach was initially overestimated, and then perceptual estimations decreased to become more accurate over feed- back blocks. Accuracy in the feedback trials themselves showed that targets just beyond reach were more difficult to judge correctly. This study establishes a straightforward methodology that can be used for calibration of actions in VEs and has implications for applications that depend on accurate reaching within VEs.","Infants’ visual experiences are important for learning, and may depend on how information is structured in the visual field. This study examined how objects are distributed in 12-month-old infants’ field of view in a mobile play setting. Infants wore a mobile eye tracker that recorded their field of view and eye movements while they freely played with toys and a caregiver. We measured how centered and spread object locations were in infants’ field of view, and investigated how infant posture, object looking, and object distance affected the centering and spread. We found that far toys were less centered in infants’ field of view while infants were prone compared to when sitting or upright. Overall, toys became more centered in view and less spread in location when infants were looking at toys regardless of posture and toy distance. In sum, this study showed that infants’ visual experiences are shaped by the physical relation between infants’ bodies and the locations of objects in the world. However, infants are able to compensate for postural and environmental constraints by actively moving their head and eyes when choosing to look at an object.","Head-mounted eye tracking is a new method that allows researchers to catch a glimpse of what infants and children see during naturalistic activities. In this chapter, we review how mobile, wearable eye trackers improve the construct validity of important developmental constructs, such as visual object experiences and social attention, in ways that would be impossible using screen-based eye tracking. Head-mounted eye tracking improves ecological validity by allowing researchers to present more realistic and complex visual scenes, create more interactive experimental situations, and examine how the body influences what infants and children see. As with any new method, there are difficulties to overcome. Accordingly, we identify what aspects of head-mounted eye tracking study design affect the measurement quality, interpretability of the results, and efficiency of gathering data. Moreover, we provide a summary of best practices aimed at allowing researchers to make well-informed decisions about whether and how to apply head-mounted eye tracking to their own research questions.","Visual attention in complex, dynamic scenes is attracted to locations that contain socially relevant features, such as faces, and to areas that are visually salient. Previous work suggests that there is a global shift over development such that observers increasingly attend to faces with age. However, no prior work has tested whether this shift is truly global, that is, consistent across and within stimuli despite variations in content. To test the global shift hypothesis, we recorded eye movements of 89 children (6 months to 10 years) and adults while they viewed 7 video clips. We measured the extent to which each participant attended to faces and to salient areas for each video. There was no evidence of global age-related changes in attention: Neither feature showed consistent increases or decreases with age. Moreover, windowed analyses within each stimulus video revealed significant moment-to-moment variations in the relation between age and each visual feature (via a bootstrapping analysis). For some time windows, adults looked more often at both feature types compared to infants and children. However, for other time windows, the pattern was reversed—younger participants looked more at faces and salient locations. Lack of consistent directional effects provides strong evidence against the global shift hypothesis. We suggest an alternative explanation: Over development, observers increasingly prioritize when and where to look by learning to track which features are relevant within a scene. Implications for the development of visual attention and children’s understanding of screen-based media are discussed.","Visual exploratory behavior refers to actively gathering visual information through coordinated eye, head, and body movements—looking around with a purpose. In this article, I compare the study of visual exploration using stationary, screen-based tasks versus mobile, naturalistic tasks. In doing so, I discuss how the ecological validity of research depends on variations in three factors: visual characteristics of stimuli, the opportunity for participants to interact with their surroundings, and participants’ ability to move their bodies. In particular, the long-standing reliance on stationary, screen tasks has precluded progress in understanding the last factor—how anatomical, biomechanical, and physiological aspects of the body influence where observers look. I argue that each factor is vital to revealing the flexibility, adaptiveness, and efficiency of everyday visual exploration.","Prior work shows that the calibration of perception and action transfers between actions depending on their functional similarity: Practising (and thus calibrating perception of) one affordance will also calibrate perception for an affordance with a similar function but not for an affordance with a disparate function. We tested this hypothesis by measuring whether calibration transferred between two affordances for passing through openings: squeezing sideways through doorways without becoming stuck and fitting sideways through doorways while avoiding collision. Participants wore a backpack to alter affordances for passage and create a need for perceptual recalibration. Calibration failed to transfer between the two actions (e.g., practising squeezing through doorways calibrated perception of squeezing but not fitting). Differences between squeezing and fitting affordances that might have required different information for perception and recalibration are explored to understand why calibration did not transfer. In light of these results, we propose a revised hypothesis—calibration transfers between affordances on the basis of both functional and informational similarity.","The first goal of this article is to review recent advances in understanding how new motor skills facilitate infants’ exploration—the active acquisition of information about their environments. New postural abilities, such as sitting and walking, qualitatively change how infants can learn about objects, places, and people with potential downstream effects on infants’ later cognitive and linguistic development. What's missing, however, is a characterization of how new exploratory abilities change infants’ everyday experiences. Presumably, changes in opportunities for learning mediate the downstream effects of posture on other developmental achievements. Accordingly, the second goal of this article is to discuss the importance of measuring the ecology of infants’ everyday experiences and how they vary.","James J. Gibson dismissed studies of “looking at” for some reasons, each of which has been influential in guiding contemporary research on naturalistic looking with the eyes and head. However, Gibson recognized that stationary eye movement recording was insufficient to study whole-body visual exploration. Task influences on visual exploration are even more striking when observers are free to engage in everyday actions that involve movement. Maintaining awareness of the visual world can be thought of as the most basic “task” of visual exploration. Gibson emphasized that a nested visual system—the eyes within the head within the body—is coordinated to visually explore one’s surroundings. Moving the head is important for minimizing extreme eye movements, however, head movements themselves should also be minimized to make visual exploration efficient because head movements are effortful. Looking ahead, we must test how observers’ active visual exploration supports perception of a stable visual world.","Changes in the body over developmental time (e.g., physical growth) as well as over shorter timescales (e.g., wearing a backpack, carrying a large object) alter possibilities for motor action. How well can children recalibrate their perception of action possibilities to account for sudden changes to body size? The current study compared younger children (4–7 years), older children (8–11 years), and adults as they decided whether they could squeeze through doorways of varying widths. To test for age-related changes in recalibration to modified abilities versus perception of unmodified abilities, half of the participants wore a backpack while making judgments and squeezing through doorways and half did not. Results indicated that judgment accuracy improved with age but that participants had more difficulty when recalibrating to modified abilities. Bias in decision making also changed with age; whereas younger children made riskier decisions by attempting to fit through impossibly small doorways, older children were more cautious. Some particularly cautious participants never generated practice feedback by attempting (and failing) to fit through smaller doorways, which prevented them from recalibrating. Taken together with previous literature, the results of the current study suggest that the development of perception for unmodified versus modified ability proceeds at different rates and depends on the particular motor task.","Developmental theories depend on characterizing the input to potential learning mechanisms—infants’ everyday experiences. The current study employed a novel ecological momentary assessment (EMA) to measure two aspects of the physical context of those experiences: body position and location. Infant body position was selected because it relates to the development of a variety of other skills. Caregivers of 3-, 6-, 9-, and 12-month-olds reported infants’ body position—held, supine, reclined, prone, sitting, or upright—in response to text message notifications over a week to capture infants’ experiences across the entire range of their daily activities. Findings revealed a tremendous disparity in the distribution of body position experiences over the first year. Younger infants spend more time held, supine, and reclined, whereas older infants spend more time sitting and upright. Body position experiences differed substantially between same-age infants who possess a motor skill (e.g., ability to sit or walk) compared with those who did not, suggesting that developing motor skills change infants’ everyday experiences. Finally, the success of the methodology suggests that similar EMAs might be used to study a wide range of infants’ naturalistic experiences.","When motor abilities change, people need to generate information to recalibrate their perception through active exploration. Most prior research has focused on observers’ ability to update perception by executing experimenter-specified exploratory behaviors, however, the question of how observers spontaneously choose how to explore has been overlooked. We asked how effectively adults decide to explore when adapting to changes in their ability to squeeze through doorways. Results revealed that participants made efficient decisions about when to explore by approaching and practicing—they most often explored doorways that were near the limit of their abilities, and participants explored less often as their perceptual calibration improved. However, participants made sub-optimal decisions about how to explore, which resulted in a failure to fully recalibrate. We discuss the implications of these findings for understanding the processes of perceptual-motor recalibration that underlie real-world behavior.","Recalibration of affordance perception in response to changing motor abilities can only occur if observers detect appropriate perceptual information. Recent work suggests that although many affordances can be recalibrated without practicing the specific action to gather outcome feedback—information about whether the attempted action succeeded or failed—calibration of other affordances might depend on outcome feedback (Franchak, Attent Percept Psychophys 79:1816–1829, 2017). However, past work could not rule out the possibility that practicing the action produced perceptual–motor feedback besides outcome feedback that facilitated recalibration. The results of two experiments support the hypothesis that recalibration in a doorway squeezing task depends on outcome feedback as opposed to perceptual–motor feedback. After putting on a backpack that changed participants’ doorway squeezing ability, affordance judgments were uncalibrated and remained so even after making repeated judgments. However, after practicing the action, which produced outcome feedback, judgments rapidly calibrated. Moreover, the order of feedback information directly impacted participants’ judgments: Participants did not recalibrate if they received only success experience or only failure experience. Recalibration only occurred after participants received both types of feedback experiences, suggesting that outcome feedback is necessary for recalibration in the doorway squeezing task. More generally, the results of the current study support a key tenet of ecological psychology—that affordance perception depends on action-specific information about body–environment relations.","Face-to-face interaction between infants and their caregivers is a mainstay of developmental research. However, common laboratory paradigms for studying dyadic interaction oversimplify the act of looking at the partner's face by seating infants and caregivers face to face in stationary positions. In less constrained conditions when both partners are freely mobile, infants and caregivers must move their heads and bodies to look at each other. We hypothesized that face looking and mutual gaze for each member of the dyad would decrease with increased motor costs of looking. To test this hypothesis, 12-month-old crawling and walking infants and their parents wore head-mounted eye trackers to record eye movements of each member of the dyad during locomotor free play in a large toy-filled playroom. Findings revealed that increased motor costs decreased face looking and mutual gaze: Each partner looked less at the other's face when their own posture or the other's posture required more motor effort to gain visual access to the other's face. Caregivers mirrored infants' posture by spending more time down on the ground when infants were prone, perhaps to facilitate face looking. Infants looked more at toys than at their caregiver's face, but caregivers looked at their infant's face and at toys in equal amounts. Furthermore, infants looked less at toys and faces compared to studies that used stationary tasks, suggesting that the attentional demands differ in an unconstrained locomotor task. Taken together, findings indicate that ever-changing motor constraints affect real-life social looking.","Young children's visual environments are dynamic, changing moment-by-moment as children physically and visually explore spaces and objects and interact with people around them. Head-mounted eye tracking offers a unique opportunity to capture children's dynamic egocentric views and how they allocate visual attention within those views. This protocol provides guiding principles and practical recommendations for researchers using head-mounted eye trackers in both laboratory and more naturalistic settings. Head-mounted eye tracking complements other experimental methods by enhancing opportunities for data collection in more ecologically valid contexts through increased portability and freedom of head and body movements compared to screen-based eye tracking. This protocol can also be integrated with other technologies, such as motion tracking and heart-rate monitoring, to provide a high-density multimodal dataset for examining natural behavior, learning, and development than previously possible. This paper illustrates the types of data generated from head-mounted eye tracking in a study designed to investigate visual attention in one natural context for toddlers: free-flowing toy play with a parent. Successful use of this protocol will allow researchers to collect data that can be used to answer questions not only about visual attention, but also about a broad range of other perceptual, cognitive, and social skills and their development."],"authors":["Franchak, J.M., & Kadooka, K.","Franchak, J.M., Scott, V., & Luo, C.","Franchak, J.M., McGee, B., & Blanch, G.","Feghhi, I., Franchak, J.M., & Rosenbaum. D.","Gagnon, H.C., Rohovit, T., Finney, H., Zhao, Y., Franchak, J.M., Stefanucci, J.K., Creem- Regehr, S.H., & Bodenheimer, R.E.","Luo, C., & Franchak, J.M.","Franchak, J.M., & Yu, C.","Kadooka, K., & Franchak, J.M.","Franchak, J.M.","Franchak, J.M.","Franchak, J.M.","Franchak, J.M.","Franchak, J.M.","Franchak, J.M.","Labinger, E., Monson, J.R., & Franchak, J.M.","Franchak, J.M. & Somoano, F.A.","Franchak, J.M., Kretch, K. S., & Adolph, K. E.","Slone, L.K., Abney, D.H., Borjon, J.I., Chen, C., Franchak, J.M., Pearcy, D., Suarez-Rivera, C., Xu, T.L., Zhang, Y., Smith, L.B., & Yu, C."],"url":["2022-FranchakKadooka-Infancy.pdf","2021-FranchakScottLuo-Frontiers.pdf","2021-FranchakMcGeeBlanch-PLoSOne",null,"2021-Gagnonetal-IEEEVR.pdf","2020-LuoFranchak-PLOSOne.pdf","2022-FranchakYu-Advances.pdf","2020-KadookaFranchak-DP.pdf","2020-Franchak-PLM.pdf","2020-Franchak-QJEP.pdf","2020-Franchak-CurrentOpinion.pdf","2020-Franchak-GibsonBook.pdf","2019-Franchak-JECP.pdf","2019-Franchak-Infancy.pdf","2018-LabingerMonsonFranchak-PLoSOne.pdf","2018-FranchakSomoano-EBR.pdf","2017-FranchakKretchAdolph-DevSci.pdf",null],"citation":["Franchak, J.M., & Kadooka, K. (2022). Age differences in orienting to faces in dynamic scenes depend on face centering, not visual saliency. Infancy.","Franchak, J.M., Scott, V., & Luo, C. (2021). A contactless method for measuring full- day, naturalistic motor behavior using wearable inertial sensors. Frontiers in Psychology.","Franchak, J.M., McGee, B., & Blanch, G. (2021). Adapting the coordination of eyes and head to differences in task and environment during fully-mobile visual exploration. PLoS One.","Feghhi, I., Franchak, J.M., & Rosenbaum. D. (2021). Towards a common code for difficulty: Navigating a narrow gap is like memorizing an extra digit. Attention, Perception, & Psychophysics.","Gagnon, H.C., Rohovit, T., Finney, H., Zhao, Y., Franchak, J.M., Stefanucci, J.K., Creem- Regehr, S.H., & Bodenheimer, R.E. (2021). The effect of feedback on estimates of reaching ability in virtual reality. Proceedings of the 2021 IEEE Virtual Reality (VR), Lisbon, Portugal.","Luo, C., & Franchak, J.M. (2020). Head and body structure infants’ visual experiences during mobile, naturalistic play. PLoS One.","Franchak, J.M., & Yu, C. (2022). Beyond screen time: Using head-mounted eye tracking to study natural behavior. Advances in Child Development and Behavior, Vol 62.","Kadooka, K., & Franchak, J.M. (2020). Developmental changes in infants' and children's attention to faces and salient regions vary across and within video stimuli. Developmental Psychology.","Franchak, J.M. (2020). Visual exploratory behavior and its development. The Psychology of Learning and Motivation (Vol. 73): Gazing toward the future: Advances in eye movement theory and applications.","Franchak, J.M. (2020). Calibration of perception fails to transfer between functionally similar affordances. Quarterly Journal of Experimental Psychology.","Franchak, J.M. (2020). The ecology of infants' perceptual-motor exploration. Current Opinion in Psychology.","Franchak, J.M. (2020). Looking with the eyes and head. Perception as Information Detection: Reflections on Gibson's Ecological Approach to Visual Perception.","Franchak, J.M. (2019). Development of affordance perception and recalibration in children and adults. Journal of Experimental Child Psychology.","Franchak, J.M. (2019). Changing opportunities for learning in everyday life: Infant body position over the first year. Infancy.","Labinger, E., Monson, J.R., & Franchak, J.M. (2018). Effectiveness of spontaneous exploration when recalibrating to changing affordances. PLoS One.","Franchak, J.M. & Somoano, F.A. (2018). Rate of recalibration to changing affordances for squeezing through doorways reveals the role of feedback. Experimental Brain Research.","Franchak, J.M., Kretch, K. S., & Adolph, K. E. (2018). See and be seen: Infant-caregiver social looking during locomotor free play. Developmental Science.","Slone, L.K., Abney, D.H., Borjon, J.I., Chen, C., Franchak, J.M., Pearcy, D., Suarez-Rivera, C., Xu, T.L., Zhang, Y., Smith, L.B., & Yu, C. (2018). Gaze in action: Head-mounted eye tracking of children's dynamic visual attention during naturalistic behavior. Journal of Visualized Experiments."],"type":["Journal","Journal","Journal","Journal","Proceedings","Journal","Chapter","Journal","Chapter","Journal","Journal","Chapter","Journal","Journal","Journal","Journal","Journal","Journal"],"doi":[null,null,null,"https://doi.org/10.3758/s13414-021-02356-4",null,null,null,null,null,null,null,null,null,null,null,null,null,"https://www.jove.com/video/58496/gaze-action-head-mounted-eye-tracking-children-s-dynamic-visual"],"inpress":[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},"columns":[{"accessor":"year","name":"","type":"numeric","show":true,"filterInput":{"name":"select","attribs":{"aria-label":"Filter year","style":{"width":"100%","height":"28px"},"onChange":"function(_e){(function(event){Reactable.setFilter('cars-select', 'year', event.target.value || undefined)}).apply(event.target,[_e])}"},"children":[{"name":"option","attribs":{"value":""},"children":["All"]},{"name":"option","attribs":{},"children":["2022"]},{"name":"option","attribs":{},"children":["2021"]},{"name":"option","attribs":{},"children":["2020"]},{"name":"option","attribs":{},"children":["2019"]},{"name":"option","attribs":{},"children":["2018"]}]},"maxWidth":70},{"accessor":"abstract","name":"","type":"character","show":true,"filterable":false,"cell":["","","","","","","","","","","","","","","","","",""],"details":["Abstract:  The current study investigated how infants (6-24 months), children (2-12 years), and adults differ in how visual cues—visual saliency and centering—guide their attention to faces in videos. We report a secondary analysis of Kadooka and Franchak (2020), in which observers’ eye movements were recorded during viewing of television clips containing a variety of faces. For every face on every video frame, we calculated its visual saliency (based on both static and dynamic image features) and calculated how close the face was to the center of the image. Results revealed that participants of every age looked more often at each face when it was more salient compared to less salient. In contrast, centering did not increase the likelihood that infants looked at a given face, but in later childhood and adulthood centering became a stronger cue for face looking. A control analysis determined that the age-related change in centering was specific to face looking; participants of all ages were more likely to look in the center of the image, and this center bias did not change with age. The implications for using videos in educational and diagnostic contexts are discussed.","Abstract:  How can researchers best measure infants' motor experiences in the home? Body position—whether infants are held, supine, prone, sitting, or upright—is an important developmental experience. However, the standard way of measuring infant body position, video recording by an experimenter in the home, can only capture short instances, may bias measurements, and conflicts with physical distancing guidelines resulting from the COVID-19 pandemic. Here, we introduce and validate an alternative method that uses machine learning algorithms to classify infants' body position from a set of wearable inertial sensors. A laboratory study of 15 infants demonstrated that the method was sufficiently accurate to measure individual differences in the time that infants spent in each body position. Two case studies showed the feasibility of applying this method to testing infants in the home using a contactless equipment drop-off procedure.","Abstract:  How are eyes and head adapted to meet the demands of visual exploration in different tasks and environments? In two studies, we measured the horizontal movements of the eyes (using mobile eye tracking in Studies 1 and 2) and the head (using inertial sensors in Study 2) while participants completed a walking task and a search and retrieval task in a large, outdoor environment. We found that the spread of visual exploration was greater while searching compared with walking, and this was primarily driven by increased movement of the head as opposed to the eyes. The contributions of the head to gaze shifts of different eccentricities was greater when searching compared to when walking. Findings are discussed with respect to understanding visual exploration as a motor action with multiple degrees of freedom.","Abstract:  What makes a task hard or easy? The question seems easy, but answering it has been hard. The only consensus has been that, all else being equal, easy tasks can be performed by more individuals than hard tasks, and easy tasks are usually preferred over hard tasks. Feghhi and Rosenbaum (Journal of Experimental Psychology: Human Perception and Performance, 45, 983–994, 2019) asked whether task difficulty might reflect a single amodal quantity. Based on their subjects’ two-alternative forced-choice data from tasks involving choices of tasks with graded physical and mental challenges, the authors showed that the difficulty of passing through a narrow gap rather than a wide gap was psychologically equivalent to memorizing an extra .55 digits. In the present study, we extended this approach by adding new arguments for the hypothesis that task difficulty might reflect a single amodal quantity (inspired by considerations of physics, economics, and the common code hypothesis for the study of perception and action), and we tested narrower gaps than before to see whether we would find a larger equivalent memory-digit. Consistent with our prediction, we obtained a value of .95. We suggest that our multi-modal two-alternative forced-choice procedure can pave the way toward a better understanding of task difficulty.","Abstract:  Immersive virtual environments (VEs) are most useful for training and education when viewers perceive and act accurately within them. Judgments of action capabilities within a VE provide a good measure of perceptual fidelity — the notion of how closely perception and action in the VE match that in the real world — and can also assess how perception for action may be calibrated with visual feedback based on one’s own actions. In the current study we tested judg- ments of action capabilities within a VE for two different reaching behaviors: reaching out and reaching up. Our goal was to assess whether feedback from actual reaching improves judgments and if any recalibration due to feedback differed across reaching behaviors. We first measured participants’ actual reaching out and reaching up capabilities so that feedback trials could be scaled to their actual abil- ities. Participants then completed blocks of alternating perceptual adjustment and feedback trials. In adjustment trials, they adjusted a virtual target to a distance perceived to be just reachable. In feedback trials, they viewed targets that were farther or closer than their actual reach, decided whether the target was reachable, and then reached out to the target to receive visual feedback from a hand-held con- troller. The first feedback block manipulated the target distance to be 30% over or under actual reach and subsequent blocks decreased the deviation to 20%, 10% and 5% of actual reach. We found that for both reaching behaviors, reach was initially overestimated, and then perceptual estimations decreased to become more accurate over feed- back blocks. Accuracy in the feedback trials themselves showed that targets just beyond reach were more difficult to judge correctly. This study establishes a straightforward methodology that can be used for calibration of actions in VEs and has implications for applications that depend on accurate reaching within VEs.","Abstract:  Infants’ visual experiences are important for learning, and may depend on how information is structured in the visual field. This study examined how objects are distributed in 12-month-old infants’ field of view in a mobile play setting. Infants wore a mobile eye tracker that recorded their field of view and eye movements while they freely played with toys and a caregiver. We measured how centered and spread object locations were in infants’ field of view, and investigated how infant posture, object looking, and object distance affected the centering and spread. We found that far toys were less centered in infants’ field of view while infants were prone compared to when sitting or upright. Overall, toys became more centered in view and less spread in location when infants were looking at toys regardless of posture and toy distance. In sum, this study showed that infants’ visual experiences are shaped by the physical relation between infants’ bodies and the locations of objects in the world. However, infants are able to compensate for postural and environmental constraints by actively moving their head and eyes when choosing to look at an object.","Abstract:  Head-mounted eye tracking is a new method that allows researchers to catch a glimpse of what infants and children see during naturalistic activities. In this chapter, we review how mobile, wearable eye trackers improve the construct validity of important developmental constructs, such as visual object experiences and social attention, in ways that would be impossible using screen-based eye tracking. Head-mounted eye tracking improves ecological validity by allowing researchers to present more realistic and complex visual scenes, create more interactive experimental situations, and examine how the body influences what infants and children see. As with any new method, there are difficulties to overcome. Accordingly, we identify what aspects of head-mounted eye tracking study design affect the measurement quality, interpretability of the results, and efficiency of gathering data. Moreover, we provide a summary of best practices aimed at allowing researchers to make well-informed decisions about whether and how to apply head-mounted eye tracking to their own research questions.","Abstract:  Visual attention in complex, dynamic scenes is attracted to locations that contain socially relevant features, such as faces, and to areas that are visually salient. Previous work suggests that there is a global shift over development such that observers increasingly attend to faces with age. However, no prior work has tested whether this shift is truly global, that is, consistent across and within stimuli despite variations in content. To test the global shift hypothesis, we recorded eye movements of 89 children (6 months to 10 years) and adults while they viewed 7 video clips. We measured the extent to which each participant attended to faces and to salient areas for each video. There was no evidence of global age-related changes in attention: Neither feature showed consistent increases or decreases with age. Moreover, windowed analyses within each stimulus video revealed significant moment-to-moment variations in the relation between age and each visual feature (via a bootstrapping analysis). For some time windows, adults looked more often at both feature types compared to infants and children. However, for other time windows, the pattern was reversed—younger participants looked more at faces and salient locations. Lack of consistent directional effects provides strong evidence against the global shift hypothesis. We suggest an alternative explanation: Over development, observers increasingly prioritize when and where to look by learning to track which features are relevant within a scene. Implications for the development of visual attention and children’s understanding of screen-based media are discussed.","Abstract:  Visual exploratory behavior refers to actively gathering visual information through coordinated eye, head, and body movements—looking around with a purpose. In this article, I compare the study of visual exploration using stationary, screen-based tasks versus mobile, naturalistic tasks. In doing so, I discuss how the ecological validity of research depends on variations in three factors: visual characteristics of stimuli, the opportunity for participants to interact with their surroundings, and participants’ ability to move their bodies. In particular, the long-standing reliance on stationary, screen tasks has precluded progress in understanding the last factor—how anatomical, biomechanical, and physiological aspects of the body influence where observers look. I argue that each factor is vital to revealing the flexibility, adaptiveness, and efficiency of everyday visual exploration.","Abstract:  Prior work shows that the calibration of perception and action transfers between actions depending on their functional similarity: Practising (and thus calibrating perception of) one affordance will also calibrate perception for an affordance with a similar function but not for an affordance with a disparate function. We tested this hypothesis by measuring whether calibration transferred between two affordances for passing through openings: squeezing sideways through doorways without becoming stuck and fitting sideways through doorways while avoiding collision. Participants wore a backpack to alter affordances for passage and create a need for perceptual recalibration. Calibration failed to transfer between the two actions (e.g., practising squeezing through doorways calibrated perception of squeezing but not fitting). Differences between squeezing and fitting affordances that might have required different information for perception and recalibration are explored to understand why calibration did not transfer. In light of these results, we propose a revised hypothesis—calibration transfers between affordances on the basis of both functional and informational similarity.","Abstract:  The first goal of this article is to review recent advances in understanding how new motor skills facilitate infants’ exploration—the active acquisition of information about their environments. New postural abilities, such as sitting and walking, qualitatively change how infants can learn about objects, places, and people with potential downstream effects on infants’ later cognitive and linguistic development. What's missing, however, is a characterization of how new exploratory abilities change infants’ everyday experiences. Presumably, changes in opportunities for learning mediate the downstream effects of posture on other developmental achievements. Accordingly, the second goal of this article is to discuss the importance of measuring the ecology of infants’ everyday experiences and how they vary.","Abstract:  James J. Gibson dismissed studies of “looking at” for some reasons, each of which has been influential in guiding contemporary research on naturalistic looking with the eyes and head. However, Gibson recognized that stationary eye movement recording was insufficient to study whole-body visual exploration. Task influences on visual exploration are even more striking when observers are free to engage in everyday actions that involve movement. Maintaining awareness of the visual world can be thought of as the most basic “task” of visual exploration. Gibson emphasized that a nested visual system—the eyes within the head within the body—is coordinated to visually explore one’s surroundings. Moving the head is important for minimizing extreme eye movements, however, head movements themselves should also be minimized to make visual exploration efficient because head movements are effortful. Looking ahead, we must test how observers’ active visual exploration supports perception of a stable visual world.","Abstract:  Changes in the body over developmental time (e.g., physical growth) as well as over shorter timescales (e.g., wearing a backpack, carrying a large object) alter possibilities for motor action. How well can children recalibrate their perception of action possibilities to account for sudden changes to body size? The current study compared younger children (4–7 years), older children (8–11 years), and adults as they decided whether they could squeeze through doorways of varying widths. To test for age-related changes in recalibration to modified abilities versus perception of unmodified abilities, half of the participants wore a backpack while making judgments and squeezing through doorways and half did not. Results indicated that judgment accuracy improved with age but that participants had more difficulty when recalibrating to modified abilities. Bias in decision making also changed with age; whereas younger children made riskier decisions by attempting to fit through impossibly small doorways, older children were more cautious. Some particularly cautious participants never generated practice feedback by attempting (and failing) to fit through smaller doorways, which prevented them from recalibrating. Taken together with previous literature, the results of the current study suggest that the development of perception for unmodified versus modified ability proceeds at different rates and depends on the particular motor task.","Abstract:  Developmental theories depend on characterizing the input to potential learning mechanisms—infants’ everyday experiences. The current study employed a novel ecological momentary assessment (EMA) to measure two aspects of the physical context of those experiences: body position and location. Infant body position was selected because it relates to the development of a variety of other skills. Caregivers of 3-, 6-, 9-, and 12-month-olds reported infants’ body position—held, supine, reclined, prone, sitting, or upright—in response to text message notifications over a week to capture infants’ experiences across the entire range of their daily activities. Findings revealed a tremendous disparity in the distribution of body position experiences over the first year. Younger infants spend more time held, supine, and reclined, whereas older infants spend more time sitting and upright. Body position experiences differed substantially between same-age infants who possess a motor skill (e.g., ability to sit or walk) compared with those who did not, suggesting that developing motor skills change infants’ everyday experiences. Finally, the success of the methodology suggests that similar EMAs might be used to study a wide range of infants’ naturalistic experiences.","Abstract:  When motor abilities change, people need to generate information to recalibrate their perception through active exploration. Most prior research has focused on observers’ ability to update perception by executing experimenter-specified exploratory behaviors, however, the question of how observers spontaneously choose how to explore has been overlooked. We asked how effectively adults decide to explore when adapting to changes in their ability to squeeze through doorways. Results revealed that participants made efficient decisions about when to explore by approaching and practicing—they most often explored doorways that were near the limit of their abilities, and participants explored less often as their perceptual calibration improved. However, participants made sub-optimal decisions about how to explore, which resulted in a failure to fully recalibrate. We discuss the implications of these findings for understanding the processes of perceptual-motor recalibration that underlie real-world behavior.","Abstract:  Recalibration of affordance perception in response to changing motor abilities can only occur if observers detect appropriate perceptual information. Recent work suggests that although many affordances can be recalibrated without practicing the specific action to gather outcome feedback—information about whether the attempted action succeeded or failed—calibration of other affordances might depend on outcome feedback (Franchak, Attent Percept Psychophys 79:1816–1829, 2017). However, past work could not rule out the possibility that practicing the action produced perceptual–motor feedback besides outcome feedback that facilitated recalibration. The results of two experiments support the hypothesis that recalibration in a doorway squeezing task depends on outcome feedback as opposed to perceptual–motor feedback. After putting on a backpack that changed participants’ doorway squeezing ability, affordance judgments were uncalibrated and remained so even after making repeated judgments. However, after practicing the action, which produced outcome feedback, judgments rapidly calibrated. Moreover, the order of feedback information directly impacted participants’ judgments: Participants did not recalibrate if they received only success experience or only failure experience. Recalibration only occurred after participants received both types of feedback experiences, suggesting that outcome feedback is necessary for recalibration in the doorway squeezing task. More generally, the results of the current study support a key tenet of ecological psychology—that affordance perception depends on action-specific information about body–environment relations.","Abstract:  Face-to-face interaction between infants and their caregivers is a mainstay of developmental research. However, common laboratory paradigms for studying dyadic interaction oversimplify the act of looking at the partner's face by seating infants and caregivers face to face in stationary positions. In less constrained conditions when both partners are freely mobile, infants and caregivers must move their heads and bodies to look at each other. We hypothesized that face looking and mutual gaze for each member of the dyad would decrease with increased motor costs of looking. To test this hypothesis, 12-month-old crawling and walking infants and their parents wore head-mounted eye trackers to record eye movements of each member of the dyad during locomotor free play in a large toy-filled playroom. Findings revealed that increased motor costs decreased face looking and mutual gaze: Each partner looked less at the other's face when their own posture or the other's posture required more motor effort to gain visual access to the other's face. Caregivers mirrored infants' posture by spending more time down on the ground when infants were prone, perhaps to facilitate face looking. Infants looked more at toys than at their caregiver's face, but caregivers looked at their infant's face and at toys in equal amounts. Furthermore, infants looked less at toys and faces compared to studies that used stationary tasks, suggesting that the attentional demands differ in an unconstrained locomotor task. Taken together, findings indicate that ever-changing motor constraints affect real-life social looking.","Abstract:  Young children's visual environments are dynamic, changing moment-by-moment as children physically and visually explore spaces and objects and interact with people around them. Head-mounted eye tracking offers a unique opportunity to capture children's dynamic egocentric views and how they allocate visual attention within those views. This protocol provides guiding principles and practical recommendations for researchers using head-mounted eye trackers in both laboratory and more naturalistic settings. Head-mounted eye tracking complements other experimental methods by enhancing opportunities for data collection in more ecologically valid contexts through increased portability and freedom of head and body movements compared to screen-based eye tracking. This protocol can also be integrated with other technologies, such as motion tracking and heart-rate monitoring, to provide a high-density multimodal dataset for examining natural behavior, learning, and development than previously possible. This paper illustrates the types of data generated from head-mounted eye tracking in a study designed to investigate visual attention in one natural context for toddlers: free-flowing toy play with a parent. Successful use of this protocol will allow researchers to collect data that can be used to answer questions not only about visual attention, but also about a broad range of other perceptual, cognitive, and social skills and their development."],"maxWidth":22},{"accessor":"authors","name":"","type":"character","show":true,"filterable":true,"cell":[{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Age differences in orienting to faces in dynamic scenes depend on face centering, not visual saliency."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Franchak, J.M., & Kadooka, K."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Infancy"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["A contactless method for measuring full- day, naturalistic motor behavior using wearable inertial sensors."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Franchak, J.M., Scott, V., & Luo, C."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Frontiers in Psychology"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Adapting the coordination of eyes and head to differences in task and environment during fully-mobile visual exploration."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Franchak, J.M., McGee, B., & Blanch, G."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["PLoS One"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Towards a common code for difficulty: Navigating a narrow gap is like memorizing an extra digit."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Feghhi, I., Franchak, J.M., & Rosenbaum. D."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Attention, Perception, & Psychophysics"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["The effect of feedback on estimates of reaching ability in virtual reality."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Gagnon, H.C., Rohovit, T., Finney, H., Zhao, Y., Franchak, J.M., Stefanucci, J.K., Creem- Regehr, S.H., & Bodenheimer, R.E."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Proceedings of the 2021 IEEE Virtual Reality (VR), Lisbon, Portugal"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Head and body structure infants’ visual experiences during mobile, naturalistic play."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Luo, C., & Franchak, J.M."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["PLoS One"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Beyond screen time: Using head-mounted eye tracking to study natural behavior."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Franchak, J.M., & Yu, C."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Advances in Child Development and Behavior, Vol 62"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Developmental changes in infants' and children's attention to faces and salient regions vary across and within video stimuli."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Kadooka, K., & Franchak, J.M."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Developmental Psychology"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Visual exploratory behavior and its development."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Franchak, J.M."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["The Psychology of Learning and Motivation (Vol. 73): Gazing toward the future: Advances in eye movement theory and applications"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Calibration of perception fails to transfer between functionally similar affordances."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Franchak, J.M."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Quarterly Journal of Experimental Psychology"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["The ecology of infants' perceptual-motor exploration."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Franchak, J.M."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Current Opinion in Psychology"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Looking with the eyes and head."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Franchak, J.M."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Perception as Information Detection: Reflections on Gibson's Ecological Approach to Visual Perception"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Development of affordance perception and recalibration in children and adults."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Franchak, J.M."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Journal of Experimental Child Psychology"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Changing opportunities for learning in everyday life: Infant body position over the first year."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Franchak, J.M."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Infancy"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Effectiveness of spontaneous exploration when recalibrating to changing affordances."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Labinger, E., Monson, J.R., & Franchak, J.M."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["PLoS One"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Rate of recalibration to changing affordances for squeezing through doorways reveals the role of feedback."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Franchak, J.M. & Somoano, F.A."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Experimental Brain Research"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["See and be seen: Infant-caregiver social looking during locomotor free play."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Franchak, J.M., Kretch, K. S., & Adolph, K. E."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Developmental Science"]}]},{"name":"div","attribs":{},"children":[{"name":"div","attribs":{},"children":["Gaze in action: Head-mounted eye tracking of children's dynamic visual attention during naturalistic behavior."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Slone, L.K., Abney, D.H., Borjon, J.I., Chen, C., Franchak, J.M., Pearcy, D., Suarez-Rivera, C., Xu, T.L., Zhang, Y., Smith, L.B., & Yu, C."]},{"name":"div","attribs":{"style":{"font-weight":"200"}},"children":["Journal of Visualized Experiments"]}]}],"minWidth":350},{"accessor":"url","name":"","type":"character","show":true,"filterable":false,"cell":[{"name":"a","attribs":{"href":"publications/2022-FranchakKadooka-Infancy.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2021-FranchakScottLuo-Frontiers.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2021-FranchakMcGeeBlanch-PLoSOne","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/NA","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2021-Gagnonetal-IEEEVR.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2020-LuoFranchak-PLOSOne.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2022-FranchakYu-Advances.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2020-KadookaFranchak-DP.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2020-Franchak-PLM.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2020-Franchak-QJEP.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2020-Franchak-CurrentOpinion.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2020-Franchak-GibsonBook.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2019-Franchak-JECP.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2019-Franchak-Infancy.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2018-LabingerMonsonFranchak-PLoSOne.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2018-FranchakSomoano-EBR.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/2017-FranchakKretchAdolph-DevSci.pdf","target":"_blank"},"children":["↓"]},{"name":"a","attribs":{"href":"publications/NA","target":"_blank"},"children":["↓"]}],"maxWidth":20},{"accessor":"citation","name":"","type":"character","show":false},{"accessor":"type","name":"","type":"character","show":true,"filterInput":{"name":"select","attribs":{"aria-label":"Filter type","style":{"width":"100%","height":"28px"},"onChange":"function(_e){(function(event){Reactable.setFilter('cars-select', 'type', event.target.value || undefined)}).apply(event.target,[_e])}"},"children":[{"name":"option","attribs":{"value":""},"children":["All"]},{"name":"option","attribs":{},"children":["Journal"]},{"name":"option","attribs":{},"children":["Proceedings"]},{"name":"option","attribs":{},"children":["Chapter"]}]},"maxWidth":115},{"accessor":"doi","name":"","type":"character","show":false},{"accessor":"inpress","name":"","type":"numeric","show":false}],"filterable":true,"defaultSortDesc":true,"defaultSorted":[{"id":"year","desc":true}],"defaultPageSize":20,"showPageSizeOptions":true,"pageSizeOptions":[20,40,60,80],"paginationType":"jump","showPageInfo":true,"minRows":1,"elementId":"cars-select","dataKey":"c267d3b2d285acaa5264a1745b83db34"},"children":[]},"class":"reactR_markup"},"evals":["tag.attribs.columns.0.filterInput.attribs.onChange","tag.attribs.columns.5.filterInput.attribs.onChange"],"jsHooks":[]}</script>
</div>
</div>
</section>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>