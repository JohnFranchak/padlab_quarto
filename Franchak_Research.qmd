--- 
execute:
  echo: false
  warning: false
format:
  html:
    toc-location: left
    toc-depth: 4
    email-obfuscation: javascript
  pdf: 
    sansfont: "Helvetica"
    geometry:
      - top=24mm
      - left=24mm
      - bottom=24mm
      - right=24mm
      - heightrounded
    fontenc: T1
    colorlinks: true
    block-headings: false
    include-in-header: 
      text: |
        \usepackage{array,colortbl}
        \arrayrulecolor{white}
        \usepackage{fancyhdr}
        \pagestyle{fancy}
        \fancyhead{}
        \fancyhead[LO,LE]{\textbf{John Franchak - Research Statement}}
        \fancyhead[RO,RE]{\thepage}
        \fancyfoot{}
        \RedeclareSectionCommand[
          beforeskip=0pt,
          afterskip=-1.25ex plus .1ex]{paragraph}
        \RedeclareSectionCommand[
          beforeskip=0pt,
          afterskip=1pt]{subsection}
---

::: {.content-visible when-format="html"}
# John Franchak - Research Statement 
{{< fa file-pdf title="Download" >}} [Download Research Statement](https://padlab.ucr.edu/Franchak_Research.pdf)
:::

\thispagestyle{fancy}

Active exploration---how people obtain information through purposeful interaction with the environment---is a key construct in theories of perception and development. My research program unravels the real-time and developmental processes that underlie how people gather perceptual information while they engage in the activities of daily living: guiding motor actions, observing scenes, and engaging in social interactions. In my lab, I currently pursue two main lines of research: (1) **How motor exploration shapes real-life opportunities for learning**, and (2) **The development of visual exploration**. I develop new methodological and computational approaches to studying behavior, such as creating a machine-learning classification system for automatically measuring infants' body position in the home from wearable inertial sensors and pioneering the first mobile eye-tracking method for studying infants’ naturalistic visual exploration.
<!-- I support open science by developing and sharing research software and by contributing datasets to Databrary and OSF repositories. -->

## Line 1: Motor exploration shapes real-life opportunities for learning

Infants' opportunities for learning about objects and people in daily life depend on how they move. In a position paper (Franchak, 2020, *Curr. Opin. Psych.*), I hypothesized that differences in the time that infants spend in different body positions---creating different opportunities for cognitive and social interactions---may facilitate later development of language and spatial cognition.

#### Detecting infants' motor experiences with inertial sensing

To characterize infants' everyday motor experiences, my mentees and I developed a new technique using wearable inertial sensors and machine learning classification to continuously measure infants' body position in the home (Franchak et al., 2021, *Frontiers in Psych.*; Franchak et al, 2024, *Beh. Res. Methods*). A **4-year NSF Developmental Sciences grant** allowed us to collect a corpus of over 850 hours of infants' real-time movement and wearable audio recording (LENA) in the home. The openly-shared (dataset)[https://nyu.databrary.org/volume/1637] establishes a public testbed for training new AI approaches for classifying movement and a large dataset for answering novel questions about infants' everyday motor behavior. My doctoral students and I have two papers under review that use the dataset to show how motor development changes the pace of everyday activities (Franchak et al., *under review*) and how infants' exposure to adults' speech depends on infants' moment-to-moment body position (Rousey et al., *revision under review*).

As the PI of a new collaborative **3-year NSF Developmental Sciences grant** that began in October, we will use the new sensing method to collect week-long movement data in infants across the United States by mailing sensors to families. Longitudinally measuring motor skill outcomes (prone, sitting, and standing) using a continuous, clinically-relevant measure (the Alberta Infant Motor Scale) will allow the proposed study to test how specific skill improvements are predicted by earlier experiences while controlling for baseline levels of motor skill. Another collaborative grant with Prof. Kari Kretch (Univ. of Southern California) uses the sensing method to measure daily motor experiences in infants with cerebral palsy, with an aim to translate measurements of typical and atypical movement to future clinical diagnosis and intervention. 
<!-- new movement opportunities model; Workshops  -->

#### Measuring infants' daily experiences with ecological momentary assessment

Testing infants at larger scales and in fully-remote applications requires methods beyond wearable sensors. In other work, I leverage text-message surveys and caregivers' smartphones to measure infants' motor experiences using ecological momentary assessment (EMA) (Franchak, 2019, *Infancy*; Franchak et al., 2024; *Dev. Psych.*). Both studies revealed that learning to walk nearly doubles the amount of time infants spend standing upright in daily life, changing their opportunities for learning about spatial and social information. I was granted a **$250k Opportunity Award from the James S. McDonnell Foundation** to gather richer data about infants' experiences using a new "video EMA" method we devised. Repeated sampling of "video snippets" will allow us to link the frequency/timing of object experiences to subsequent learning of object labels. Ongoing collaborations will apply computer vision techniques to automatically detect infant behavior from smartphone videos to create AI-driven pipelines to gather large-scale datasets about natural infant behavior.

## Line 2: The development of visual exploration

What influences where people choose to look when visually exploring scenes, and how do those influences change over development? My research considers how scene factors, task constraints, and the motor coordination influence visual exploration.

#### Bottom-up and top-down influences on attention 

Prior work suggests that the visual appearance of a target (bottom-up influences) captures the eye gaze of young infants, but older infants' gaze is driven more by a target's meaning (top-down influences). Across a series of papers, my mentees and I challenged this view by recording infant, child, and adult eye movements while watching video clips (Kadooka & Franchak, 2020, *Dev. Psych.*; Franchak & Kadooka, 2022, *Infancy*; Jing et al., 2023, *JECP*). Using a wider set of videos and range of ages than in prior work, we failed to find evidence of a global age-related shift in attention from bottom-up to top-down features. Instead, participants of all ages prioritized which features are most important to attend to from moment to moment, which varied according to the scene. Moreover, we found that media conventions (e.g., centering of faces in the scene) more strongly influence fixations to faces in videos compared with bottom-up saliency in both infants and children. These findings have implications for using social attention as a biomarker for autism and also for designing educational media to better direct children's attention.

#### Exploring with eyes, head, and body 

Beyond screen-based tasks, it is important to consider that looking is a motor action---observers must coordinate movements of their eyes, heads, and bodies to look in different directions (Franchak, 2020, *Psych. of Learning & Motivation*). How does the motor act of looking shape how observers visually explore, and how do motor influences change over development? In earlier work, I used mobile eye trackers to reveal that infants' body position shapes what they see (Franchak et al., 2011, *Chi Dev*; Kretch, Franchak, & Adolph, 2014, *Chi. Dev.*). Notably, a paper in *Dev. Sci.* described how infants' real-time body position affects social gaze (Franchak et al., 2018): Infants less often see caregivers’ faces while infants are crawling than while they are sitting or upright. We extended this to ask how infants learn to orient their heads to center information in view: Infants can more easily center objects in view when they are in a sitting position compared with when they are prone (Luo & Franchak, 2020, *PLoS ONE*). I also identified developmental changes in how infants orient their heads to center faces versus objects (Franchak et al., 2024, *Dev. Psychobiol.*). Recent projects test how the coordination of eyes and head support visual exploration in adults. By pairing inertial sensing (to measure head rotation) with mobile eye tracking, my mentees and I found that adults' search in a large outdoor environment is driven more by modifying head movements compared with eye movements (Franchak et al., 2021, *PLoS ONE*). We also discovered that the need to engage lower effort (eyes) versus higher effort (head, body) effectors to visually explore shapes adults' real-time information-gathering decisions when visual targets are placed in different locations (Luo & Franchak, 2022, 2025, *Collabra: Psychology*).

<!-- ![Left: Infant wearing mobile eye tracker; cameras capture the eye and field of view. Right: Differences in visual experiences of objects for infants in sitting versus prone postures.](images/et-fov.pdf) -->

#### Methodological contributions 

To facilitate this work, I led the development of the first mobile eye tracking methodology to measure visual exploration in freely-moving infants (Franchak et al., 2011, *Chi Dev*). I have co-organized two pre-conference workshops, contributed four tutorial papers (Franchak, 2017, *Cambridge Ency.*; Slone et al., 2018, *JOVE*; Franchak & Yu, 2022, *Advances in Child Devel.*; Fu et al., 2024, *Beh. Res. Method.*), and collaborated on the development of computer vision analyses (Lee et al., 2014, *IEEE CVPR*) to help other researchers adopt the method. I was recognized as an APS Rising Star and a Visiting Scholar at the McPherson Eye Research Institute in recognition of these contributions.
<!-- I actively maintain open source [software tools](https://padlab.ucr.edu/Tools.html) that aid mobile eye tracking analyses.  -->



<!-- ## Line 3: Exploratory behavior calibrates perception of action possibilities -->

<!-- Possibilities for action depend on the fit between the body and the environment. For example, whether it is possible to walk under a tree branch without hitting the head depends on body height relative to the height of the branch. Perceiving possibilities for action is a challenge because bodies change in size, requiring *recalibration* of perception.  -->

<!-- #### Real-time learning from exploratory practice  -->

<!-- My studies reveal that successful recalibration to changes in body size depends on whether people explore in ways that generate information about how action possibilities have changed. My mentees and I published 5 papers while at UCR to disentangle *why* practice performing an action leads to recalibration for some actions but not for others (Franchak, 2017, *APP*; Labinger et al., 2018, *PLoS ONE*; Franchak & Somoano, 2018, *EBR*; Franchak, 2020, *QJEP*; Gagnon et al., 2021, *IEEE VR*). Does practice simply provide a way to generate movement experience, or is outcome feedback (successfully performing vs. failing) important for recalibration? In a "squeezing through doorways task", I found that participants who only received movement experience without outcome feedback (walking around the lab and pressing the backpack against a wall) failed to recalibrate, suggesting that practice recalibrates perception because it provides outcome feedback. In later papers we showed that the role of outcome feedback is task-dependent: Outcome feedback does not calibrate perception in a fitting (compared to squeezing) version of the task, and the role of feedback differs for judgments of vertical versus horizontal reaching. -->

<!-- #### Development of exploration for perceptual-motor recalibration -->

<!-- Perception of possibilities for action improves through infancy and childhood (Franchak & Adolph, 2012, *Dev Psych*; Ishak et al., 2014, *JECP*). More recently, I showed that the ability to **recalibrate** improves from 4 to 11 years (Franchak, 2019, *JECP*). Although 11-year-olds show an adult-like ability to perceive their unaltered abilities, they lag behind adults in a recalibration task. My work implies that changes in body size may increase the likelihood of motor errors; children’s deficit in recalibration may contribute to higher rates of accidental injury in childhood.  -->
